{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhE_6teQ5EjY",
    "outputId": "fe6ac105-13f9-46a9-866d-19b6c6a7ba78"
   },
   "outputs": [],
   "source": [
    "!pip install datasets pillow torch torchvision --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368,
     "referenced_widgets": [
      "313f8c94005b4c0da05ad85d976cf71b",
      "0c07ccbc1e6c4276b2565a9045d863bc",
      "6db28539c07f45e6929ca78b6a5f6454",
      "05796a53ff054b60803779442246be9a",
      "2c5274c2ab3f4083aece5dd7c46f058a",
      "a81ced1500534f6bbbe94aa960a3f4c4",
      "856aa2af067949989d082174ae2192bb",
      "b807198f0770405fa0914e124a5af10b",
      "7fc24af618a742a6ac8d18949179770d",
      "18588b26c63e48b4982615014391d219",
      "8d5416df505745f99d9b38b24bc156c9",
      "33066d4f27c745f780848ba99558a56b",
      "8e6b03c70ef641acbcc99bbf23041d7b",
      "a919141b4915422a875a6e0c8a9683ac",
      "d35ebf7e69154d16b2a739ec865cb198",
      "4d4a721a282645c6ab91b6bd43b0fce8",
      "503344d557bc4a7598ac0b1f49862586",
      "86f9eb09b7fa48e8a3c05d83f6440d60",
      "ea41b4ea658a4c56a0007039ed1934ec",
      "9c53eb4a1fdb46e587c9f99521a60ebd",
      "7dd1c49263624343a34070999cd1d4e0",
      "d98da735b96b481b9da7f375a73827e8",
      "35d490eb626344508ac001b9c43b884d",
      "543534284dea430e925e8b63ce4b4627",
      "036bc1b2bcb9471db6847fb539b536ed",
      "f912756d00de4e66a43282cc9536ab02",
      "6fb1495f71f1449da5920c5b1efa4c7b",
      "830f431bd668421cb3625748e5a2a2bb",
      "3a4ea4f23a6f40f298b2163bd98e69e8",
      "90d4ea1909294dd390374272c85ea473",
      "8e13a372774f48eb89cddfa7521b7d03",
      "9d66d51b7fa44434bf3292ab7bc3bfdf",
      "e0f250df885e4464a691d7f70bb64114",
      "9fb2baf70bb04f8f8cb498c92d14809e",
      "e1c39790778743f49461702d35f93be3",
      "47a43027117d45f8966c6f8b6378afa2",
      "e8c774bc995246a2b22555fdf74fcad4",
      "6b5e0485c8514b858b80d9d2b6cae564",
      "39afff90a56c449a86603ea8c384de48",
      "331b66eb3e3649e199a92e8a12a00b48",
      "0d3fc92073c344fe840f867ce9fce684",
      "31255d85c4694f51bcbb795637dca27d",
      "6f22980ecddf44c1aee02c093f7e5a9b",
      "011d5fb47b52480e88f27f115e1d250c",
      "f81f53e106d14977a8594a3814d0f2c1",
      "e5f4ba46a5394593b9456c698685411e",
      "0d24a21af95e4dde8846ec8bf6411867",
      "4d5de68e2fb34278ae3be817956a9005",
      "3078c5e68fca4a1c8e6ba9dc20cc62b5",
      "507feaba90f949f5a8a3421f13da78a4",
      "816b0fd2e1bb4281a943ded47f7d6389",
      "bb6843fae01d48ee947bf2027d3c6eea",
      "269526dae48a466cb7a1ebdeb8bd2df3",
      "0466de49ca724de0a70fa8151d559a01",
      "d408011c45ff4e5ca6cc5c646dc3e596",
      "039b53e649d44f6c85d48df6f94fa6fe",
      "5a032ae4274f4cd9bc49ac1f2ec65bca",
      "78150ad3e7c546039a4a55330d84d6cf",
      "1c5f7264841d48fba5be8f497de82c51",
      "bfe802d2c48f4337b5fe99012c21c904",
      "006b5bd1533d47478110f55c494e5ebb",
      "39b5a1c1378646c2a3f17e9b9c25c969",
      "b9d290e4ab8944149693d9ca75ee1d6e",
      "1b5bc650134f40898dd347dbd84c311b",
      "f0f4cd9eb8f5461aa8354292f7c5f303",
      "268353d1a7cb4c14808a0aba3eca1d0d",
      "7fbcc52057fe40efafd0126251f28e9d",
      "e4f8f7909a494f299b852807ea806875",
      "b14b47acdbb24d68af908d12024994c3",
      "70e8c0fcb72643bd867048aa5dff06be",
      "daadfe6164804bd5b7c4d3f991a2954d",
      "90c621fcfedd482b81124cd5917fcae7",
      "a7d651589fa94b7fa622d09d0b75743a",
      "c4afc6e40fd749bdb48d64212082593b",
      "d1ad5c85464f43a4be11657641393a55",
      "2905d4e116744ef2b1c8897e17a50abf",
      "defeb379908048f2b8a623213597bb47"
     ]
    },
    "id": "j0_f07W_5Jep",
    "outputId": "96612c1c-1dec-49fa-8384-525b4734f2d7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "\n",
    "# Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"Hemg/deepfake-and-real-images\", split=\"train\")\n",
    "\n",
    "# Define image transformation (resize, convert to tensor, normalize)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize to 128x128\n",
    "    transforms.ToTensor(),           # Convert to Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize (mean=0.5, std=0.5)\n",
    "])\n",
    "\n",
    "# Custom PyTorch Dataset class\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx][\"image\"]\n",
    "        label = self.dataset[idx][\"label\"]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)  # Return as Tensor\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = DeepfakeDataset(dataset, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vFuVZt15LVW",
    "outputId": "b8352e28-6bb8-45c9-d384-57fa4f84cb91"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define split ratio\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"✅ Dataset Loaded: {train_size} training images, {val_size} validation images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "Mm2VxZpY5NQN",
    "outputId": "57e38d19-495c-4b99-db21-134b6fa18025"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get one batch of images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Display some images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "for i in range(5):\n",
    "    img = images[i].permute(1, 2, 0).numpy()  # Convert to NumPy for visualization\n",
    "    img = (img * 0.5) + 0.5  # Unnormalize\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Label: {'Fake' if labels[i] == 1 else 'Real'}\")\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyFMYFvh5PL_",
    "outputId": "94680dda-863d-4f05-cd72-22ee5db77128"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple CNN model\n",
    "class DeepfakeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepfakeCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 16 * 16, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Create model instance\n",
    "model = DeepfakeCNN()\n",
    "\n",
    "# Define optimizer & loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy for deepfake classification\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Train for 5 epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.float().to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(\"✅ Model Training Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_QkdkfU5REF",
    "outputId": "22720e55-6e0d-4df7-e509-2b6517b825fb"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"deepfake_cnn.pth\")\n",
    "print(\"✅ Model saved as deepfake_cnn.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "e-BQH_x6YKxS",
    "outputId": "01f1ffec-d22a-44ed-e570-81d0600128b3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions & true labels\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:  # Use validation dataset\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)  # Get model predictions\n",
    "        probs = outputs.cpu().numpy()  # Convert to NumPy\n",
    "        preds = (outputs > 0.5).cpu().numpy().astype(int)  # Convert to 0 or 1\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "        all_preds.extend(preds)  # Store predictions\n",
    "        all_probs.extend(probs)  # Store probability scores\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Compute Evaluation Metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "auc_roc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "# Print Evaluation Results\n",
    "print(f\"🔹 Accuracy: {accuracy:.4f}\")\n",
    "print(f\"🔹 Precision: {precision:.4f}\")\n",
    "print(f\"🔹 Recall: {recall:.4f}\")\n",
    "print(f\"🔹 F1 Score: {f1:.4f}\")\n",
    "print(f\"🔹 AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'AUC-ROC = {auc_roc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3g19mfEcvONI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "\n",
    "# Make sure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = (outputs > 0.5).int()  # Convert sigmoid to binary class\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "Qu4vK_93wO45",
    "outputId": "b358f119-c068-4bcc-ba27-1fa400a80406"
   },
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Optional: plot it\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "ozhnsbfna2XO",
    "outputId": "e8fd9a15-bf63-4187-979d-de46d6b04cd9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the CNN architecture (same as the one used for training)\n",
    "class DeepfakeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepfakeCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 16 * 16, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepfakeCNN().to(device)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load(\"/content/deepfake_cnn.pth\", map_location=device))\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
